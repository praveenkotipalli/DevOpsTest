pipeline {
    agent any
    
    environment {
        JMETER_HOME = tool 'JMeter'
        JAVA_HOME = tool 'JDK17'
        MAVEN_HOME = tool 'Maven'
    }
    
    tools {
        jdk 'JDK17'
        maven 'Maven'
        jmeter 'JMeter'
    }
    
    stages {
        stage('Checkout') {
            steps {
                echo '🔍 Checking out source code...'
                checkout scm
            }
        }
        
        stage('Build') {
            steps {
                echo '⚙️ Building application...'
                sh 'mvn clean compile'
            }
        }
        
        stage('Unit Tests') {
            steps {
                echo '🧪 Running unit tests...'
                sh 'mvn test'
            }
            post {
                always {
                    publishTestResults testResultsPattern: '**/surefire-reports/*.xml'
                }
            }
        }
        
        stage('Performance Testing') {
            steps {
                echo '📊 Running JMeter performance tests...'
                script {
                    // Run JMeter tests and collect metrics
                    sh '''
                        cd jmeter
                        ./run-tests.sh
                        
                        # Convert JMeter results to Prometheus metrics
                        python3 -c "
import json
import os
from datetime import datetime

# Parse JMeter results and create Prometheus metrics
results_file = 'results/load-test.jtl'
if os.path.exists(results_file):
    with open(results_file, 'r') as f:
        lines = f.readlines()
    
    # Extract metrics (simplified parsing)
    total_requests = len([l for l in lines if '200' in l])
    failed_requests = len([l for l in lines if '500' in l or '404' in l])
    
    # Create Prometheus metrics file
    metrics = f'''# JMeter Performance Test Results
# Generated at {datetime.now().isoformat()}
jmeter_total_requests{{test="load_test"}} {total_requests}
jmeter_failed_requests{{test="load_test"}} {failed_requests}
jmeter_success_rate{{test="load_test"}} {(total_requests - failed_requests) / total_requests if total_requests > 0 else 0}
'''
    
    with open('results/prometheus_metrics.txt', 'w') as f:
        f.write(metrics)
"
                    '''
                }
            }
            post {
                always {
                    // Archive JMeter results
                    archiveArtifacts artifacts: 'jmeter/results/**/*', fingerprint: true
                    archiveArtifacts artifacts: 'jmeter/reports/**/*', fingerprint: true
                    
                    // Publish performance test results
                    publishPerformanceTestResults performanceTestResults: [
                        [name: 'Load Test', resultFile: 'jmeter/results/load-test.jtl'],
                        [name: 'Stress Test', resultFile: 'jmeter/results/stress-test.jtl'],
                        [name: 'Spike Test', resultFile: 'jmeter/results/spike-test.jtl']
                    ]
                }
            }
        }
        
        stage('Metrics Collection') {
            steps {
                echo '📈 Collecting performance metrics...'
                script {
                    // Send metrics to Prometheus
                    sh '''
                        # Create metrics endpoint for Prometheus to scrape
                        echo "Creating metrics endpoint..."
                        
                        # Generate build metrics
                        BUILD_TIME=$(date +%s)
                        BUILD_DURATION=$((BUILD_TIME - ${BUILD_TIMESTAMP:-$BUILD_TIME}))
                        
                        cat > metrics.txt << EOF
# Jenkins Build Metrics
jenkins_build_duration_seconds{build_id="${BUILD_NUMBER}",job="${JOB_NAME}"} ${BUILD_DURATION}
jenkins_build_status{build_id="${BUILD_NUMBER}",job="${JOB_NAME}"} 1
jenkins_build_timestamp{build_id="${BUILD_NUMBER}",job="${JOB_NAME}"} ${BUILD_TIME}
EOF

                        # Copy metrics to a location Prometheus can access
                        cp metrics.txt /tmp/jenkins_metrics.txt
                        cp jmeter/results/prometheus_metrics.txt /tmp/jmeter_metrics.txt 2>/dev/null || echo "No JMeter metrics found"
                    '''
                }
            }
        }
        
        stage('Deploy Decision') {
            steps {
                echo '🤔 Evaluating deployment criteria...'
                script {
                    // Check if performance tests passed
                    def jmeterResults = readFile('jmeter/results/prometheus_metrics.txt').trim()
                    def successRate = (jmeterResults =~ /jmeter_success_rate.*?(\d+\.?\d*)/)[0][1] as Double
                    
                    if (successRate >= 0.95) {
                        echo "✅ Performance tests passed! Success rate: ${successRate * 100}%"
                        currentBuild.result = 'SUCCESS'
                    } else {
                        echo "❌ Performance tests failed! Success rate: ${successRate * 100}%"
                        currentBuild.result = 'FAILURE'
                        error("Performance tests did not meet threshold (95%)")
                    }
                }
            }
        }
        
        stage('Deploy to Docker') {
            when {
                expression { currentBuild.result == 'SUCCESS' }
            }
            steps {
                echo '🚀 Deploying to Docker...'
                script {
                    // Build and run Docker container
                    sh '''
                        docker build -t devops-performance-demo:${BUILD_NUMBER} .
                        docker stop devops-app || true
                        docker rm devops-app || true
                        docker run -d --name devops-app -p 8080:8080 devops-performance-demo:${BUILD_NUMBER}
                        
                        # Wait for app to start
                        sleep 10
                        
                        # Health check
                        if curl -f http://localhost:8080/health; then
                            echo "✅ Application deployed successfully!"
                        else
                            echo "❌ Application deployment failed!"
                            exit 1
                        fi
                    '''
                }
            }
            post {
                success {
                    echo '🎉 Deployment successful!'
                    // Send deployment success metric
                    sh '''
                        echo "jenkins_deployment_success{build_id=\"${BUILD_NUMBER}\",job=\"${JOB_NAME}\"} 1" >> /tmp/jenkins_metrics.txt
                    '''
                }
                failure {
                    echo '💥 Deployment failed!'
                    // Send deployment failure metric
                    sh '''
                        echo "jenkins_deployment_success{build_id=\"${BUILD_NUMBER}\",job=\"${JOB_NAME}\"} 0" >> /tmp/jenkins_metrics.txt
                    '''
                }
            }
        }
    }
    
    post {
        always {
            echo '🧹 Cleaning up...'
            // Clean up temporary files
            sh 'rm -f metrics.txt /tmp/jenkins_metrics.txt /tmp/jmeter_metrics.txt 2>/dev/null || true'
        }
        success {
            echo '🎉 Pipeline completed successfully!'
        }
        failure {
            echo '💥 Pipeline failed!'
        }
    }
}
